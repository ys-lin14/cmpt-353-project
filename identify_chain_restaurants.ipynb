{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster, linkage\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from extract_transform import get_match, get_chain_restaurant_qids, get_num_chain_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - add docstrings, maybe move functions to modules\n",
    "def llf(leaf_id): # leaf label func for dendrogram adapted from scipy docs\n",
    "    \"\"\"Map leaf_id (index) to Wikidata name\n",
    "    \n",
    "    Args:\n",
    "        leaf_id (int):\n",
    "    \n",
    "    Returns:\n",
    "        leaf_name (str):\n",
    "    \"\"\"\n",
    "    \n",
    "    leaf_name = wikidata.loc[leaf_id, 'name']\n",
    "    return leaf_name\n",
    "\n",
    "# map names to red if their wikidata description contains 'chain' and 'restaurant'\n",
    "def get_color(ylabel): \n",
    "    try:\n",
    "        color = color_dict[ylabel.get_text()]\n",
    "    except:\n",
    "        color = 'blue'\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_data = pd.read_json('data/preprocessed-osm-data.json.gz')\n",
    "\n",
    "raw_wikidata = pd.read_json('data/wikidata.json')\n",
    "preprocessed_wikidata = pd.read_json('data/preprocessed-wikidata.json')\n",
    "wikidata = raw_wikidata.merge(preprocessed_wikidata, on='qid')\n",
    "\n",
    "wikidata['name'] = wikidata['names'].apply(lambda names: names[0])\n",
    "descriptions = wikidata['preprocessed_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to identify chain restaurants by determining which Wikidata entries are about chain restaurants and mapping the results back to the OSM data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_chain = wikidata['preprocessed_description'].apply(\n",
    "    lambda description: get_match('chain', description)\n",
    ").notna()\n",
    "\n",
    "contains_restaurant = wikidata['preprocessed_description'].apply(\n",
    "    lambda description: get_match('restaurant', description)\n",
    ").notna()\n",
    "contains_chain_and_restaurant = (contains_chain & contains_restaurant)\n",
    "\n",
    "chain_restaurant_wikidata = wikidata[contains_chain_and_restaurant]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we start off with a regex approach which assumes that a Wikidata entry is about a chain restaurant if its description contains both the words 'chain' and 'restaurant'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check for both 'chain' and 'restaurant' based on how checking for 'chain' alone can potentially result in more false positives since it can also describe non-restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include entries that contain the words 'chain' and 'restaurant'\n",
    "chain_restaurant_wikidata = wikidata[contains_chain_and_restaurant]\n",
    "chain_restaurant_qids = get_chain_restaurant_qids(chain_restaurant_wikidata)\n",
    "\n",
    "# map back to OSM data to get the number of chain restaurants\n",
    "num_chain_restaurants = get_num_chain_restaurants(osm_data, chain_restaurant_qids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chain_restaurant_qids = len(chain_restaurant_qids)\n",
    "print('Number of Wikidata Entries about Chain Restaurants: ', end='')\n",
    "print(num_chain_restaurant_qids)\n",
    "print(f'Number of Chain Restaurants: {num_chain_restaurants}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regex approach considers 38 Wikidata entries to be about chain restaurants and 691 OSM locations to be chain restaurants. Limitations of the regex approach include how it may result in false negatives and underestimate the number of chain restaurants due to how descriptions for some chain restaurants may not contain both the words 'chain' and 'restaurant'.\n",
    "\n",
    "Based on these limitations we move on to a mixed approach which uses the regex results in addition to clustering with cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine similarities between each Wikidata description\n",
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "document_term_matrix = vectorizer.fit_transform(descriptions)\n",
    "cosine_similarities = cosine_similarity(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get names of chain restaurants that will later be used for dendrogram labels \n",
    "chain_restaurant_names = chain_restaurant_wikidata['name'].values\n",
    "# color names associated with wikidata descriptions that contain 'chain' and 'restaurant' red\n",
    "# -> compare regex predictions with cosine similarity clusters\n",
    "color_dict = {}\n",
    "for name in chain_restaurant_names:\n",
    "    color_dict[name] = 'r'\n",
    "    \n",
    "# scipy dendrogram docs\n",
    "Z = linkage(cosine_similarities, method='complete')\n",
    "\n",
    "# LOOKS UGLY ON GITLAB USE https://kokes.github.io/nbviewer.js/viewer.html\n",
    "fig = plt.figure(figsize=(20, 60)) \n",
    "dn = dendrogram(Z, leaf_label_func=llf, orientation='left', leaf_font_size=20) \n",
    "\n",
    "# label coloring adapted from Warren Weckesser's answer at \n",
    "# https://stackoverflow.com/questions/14802048/\n",
    "ax = plt.gca()\n",
    "ylabels = ax.get_ymajorticklabels()\n",
    "for ylabel in ylabels:\n",
    "    ylabel.set_color(get_color(ylabel))\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=20)\n",
    "\n",
    "plt.axvline(x=3.5, linestyle='-.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = llf(wikidata.index) # get names given index \n",
    "clusters = fcluster(Z, t=3, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe containing columns for name and cluster\n",
    "name_cluster = pd.DataFrame.from_dict(\n",
    "    dict(zip(names, clusters)), \n",
    "    orient='index'\n",
    ").reset_index().rename(columns={'index': 'name', 0:'cluster'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the cluster with the most chain restaurants \n",
    "chain_restaurant_wikidata = chain_restaurant_wikidata.merge(name_cluster, on='name')\n",
    "chain_restaurant_cluster = chain_restaurant_wikidata['cluster'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_within_chain_restaurant_cluster = (name_cluster['cluster'] == chain_restaurant_cluster)\n",
    "is_chain_restaurant = (contains_chain_and_restaurant | is_within_chain_restaurant_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# include entries within the cluster with the most chain restaurants \n",
    "updated_chain_restaurant_wikidata = wikidata[is_chain_restaurant]\n",
    "updated_chain_restaurant_qids = get_chain_restaurant_qids(updated_chain_restaurant_wikidata)\n",
    "\n",
    "# map back to OSM data to get the updated number of chain restaurants\n",
    "updated_num_chain_restaurants = get_num_chain_restaurants(osm_data, updated_chain_restaurant_qids)\n",
    "\n",
    "display_num_chain_qid_restaurants(updated_chain_restaurant_qids, updated_num_chain_restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_num_chain_restaurant_qids = len(updated_chain_restaurant_qids)\n",
    "print('Number of Wikidata Entries about Chain Restaurants: ', end='')\n",
    "print(updated_num_chain_restaurant_qids)\n",
    "print(f'Number of Chain Restaurants: {num_chain_restaurants}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write updated_chain_restaurant_qids to json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster correctly groups some chain restaurants with descriptions that do not contain the words\n",
    "'chain' or 'restaurant'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
